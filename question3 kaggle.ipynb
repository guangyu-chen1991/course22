{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import time \n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,x,y):\n",
    "        self.data = x\n",
    "        self.targets = y.astype('int64')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        transform = T.Compose([ T.ToTensor() ])\n",
    "        return transform(x)  ,  self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 0 has been load in training set\n"
     ]
    }
   ],
   "source": [
    "# 数据集的子目录名称\n",
    "classes = [\"REAL\",\"FAKE\"]\n",
    "x, y = [],[]\n",
    "# 定义REAL为标签0，FAKE为标签1\n",
    "class_dict = {'REAL':0, 'FAKE':1}\n",
    "\n",
    "# 读取图片\n",
    "for c in classes:\n",
    "    # 遍历目录进行读取\n",
    "    paths = glob.glob('D:/UQ 2023 semester1/image processing elec4630/assignment3/q3/archive/train/'+c+'/*')\n",
    "    for p in paths:\n",
    "        # 使用PIL的Image模块进行读取\n",
    "        img = Image.open(p)\n",
    "        # 将PIL图像转换为numpy array\n",
    "        imgarray = np.asarray(img)\n",
    "        # 把numpy array格式的图像，以及标签添加到x和y\n",
    "        x.append(imgarray)\n",
    "        y.append(class_dict[c]) \n",
    "\n",
    "# 转化为numpy array形式，用于构建dataset\n",
    "x , y = np.array(x), np.array(y)\n",
    "\n",
    "print(\"=> {} has been load in training set\".format(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_set = Dataset(x, y)\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 0 has been load in testing set\n"
     ]
    }
   ],
   "source": [
    "x, y = [],[]\n",
    "for c in classes:\n",
    "    paths = glob.glob('./archive/test/'+c+'/*')\n",
    "    for p in paths:\n",
    "        img = Image.open(p)\n",
    "        # resize成统一维度\n",
    "        imgarray = np.asarray(img)\n",
    "        x.append(imgarray)\n",
    "        y.append(class_dict[c]) \n",
    "\n",
    "x , y = np.array(x), np.array(y)\n",
    "\n",
    "print(\"=> {} has been load in testing set\".format(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = Dataset(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_set, val_set \u001b[39m=\u001b[39m random_split(dataset\u001b[39m=\u001b[39;49mtrain_set,lengths\u001b[39m=\u001b[39;49m[\u001b[39m80000\u001b[39;49m, \u001b[39m20000\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m \u001b[39m# 然后将测试集划分为400的测试集和273的验证集\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 查看图片数量是否相符\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Set, Validatoin Set, Testing set:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:353\u001b[0m, in \u001b[0;36mrandom_split\u001b[0;34m(dataset, lengths, generator)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m# Cannot verify that dataset is Sized\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39msum\u001b[39m(lengths) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(dataset):    \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSum of input lengths does not equal the length of the input dataset!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    355\u001b[0m indices \u001b[39m=\u001b[39m randperm(\u001b[39msum\u001b[39m(lengths), generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m [Subset(dataset, indices[offset \u001b[39m-\u001b[39m length : offset]) \u001b[39mfor\u001b[39;00m offset, length \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(_accumulate(lengths), lengths)]\n",
      "\u001b[0;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "train_set, val_set = random_split(dataset=train_set,lengths=[80000, 20000])\n",
    "# 然后将测试集划分为400的测试集和273的验证集\n",
    "# 查看图片数量是否相符\n",
    "print('Training Set, Validatoin Set, Testing set:')\n",
    "print(len(train_set), len(val_set), len(test_set))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
